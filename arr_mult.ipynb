{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Element-wise multiplication of two arrays "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Managed Device 0>\n"
     ]
    }
   ],
   "source": [
    "print(cuda.gpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CPU method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multip(a,b,c):\n",
    "    for i in range(len(a)):\n",
    "        c[i] = a[i]*b[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### input arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100000000\n",
    "a = np.full(n, 2.12474, dtype = np.float32)\n",
    "b = np.full(n, 3.12445, dtype = np.float32)\n",
    "c = np.empty_like(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29.2 s, sys: 152 ms, total: 29.4 s\n",
      "Wall time: 29.4 s\n"
     ]
    }
   ],
   "source": [
    "%time multip(a, b, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.6386433 6.6386433 6.6386433 ... 6.6386433 6.6386433 6.6386433]\n"
     ]
    }
   ],
   "source": [
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GPU kernel: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit('void(float32[:], float32[:], float32[:])')\n",
    "def cuda_mult(a,b,c):\n",
    "    \"\"\"This kernel function will be executed by a thread.\"\"\"\n",
    "    i = cuda.blockIdx.x * cuda.blockDim.x + cuda.threadIdx.x\n",
    "    if i > c.size:\n",
    "        return\n",
    "    c[i] = a[i]*b[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Memory allocation on GPU and arrays copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = cuda.get_current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device.WARP_SIZE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_a = cuda.to_device(a)\n",
    "d_b = cuda.to_device(b)\n",
    "d_c = cuda.device_array_like(a)\n",
    "\n",
    "tpb = device.WARP_SIZE       #blocksize or thread per block\n",
    "bpg = int(np.ceil((n)/tpb))  #block per grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 3125000, 100000000)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpb, bpg, tpb*bpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blockspergrid = (n.size + (tpb - 1)) // tpb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.25 ms, sys: 68 µs, total: 1.32 ms\n",
      "Wall time: 924 µs\n"
     ]
    }
   ],
   "source": [
    "%time cuda_mult[bpg, tpb](d_a, d_b, d_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.6386433 6.6386433 6.6386433 ... 6.6386433 6.6386433 6.6386433]\n"
     ]
    }
   ],
   "source": [
    "# Transfer output from device to host\n",
    "c = d_c.copy_to_host()\n",
    "print (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000000"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Race condition:\n",
    "\n",
    "CUDA, like many general purpose parallel execution frameworks, makes it possible to have race condtions in your code. A race condition in CUDA arises when **threads read or write a memory location that might be modified by another independent thread**. Generally speaking, you need to worry about:\n",
    "\n",
    "* `read-after-write hazards`: One thread is reading a memory location at the same time another thread might be writing to it.\n",
    "* `write-after-write hazards`: Two threads are writing to the same memory location, and only one write will be visible when the kernel is complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit('void(int32[:])')\n",
    "def thread_counter_race_condition(global_counter):\n",
    "    global_counter[0] += 1  # This is bad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every thread increments a global counter.\n",
    "\n",
    "1. Read the current value of a global counter.\n",
    "2. Compute counter + 1.\n",
    "3. Write that value back to global memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_counter = np.array([0], dtype=np.int32)  \n",
    "d_global_counter = cuda.to_device(global_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbp=64\n",
    "bpg=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Should be 4096: [1]\n"
     ]
    }
   ],
   "source": [
    "thread_counter_race_condition[bpg, tbp](d_global_counter)\n",
    "\n",
    "print('Should be %d:' % (tbp*bpg), d_global_counter.copy_to_host())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
